**문제 상황**
nova-conductor 프로세스와 apache2 프로세스(웹 서버)가 커널 레벨에서 오랫동안 스케줄링되지 못하고(blocked) 멈춰 있는 상황
![[Pasted image 20251002155729.png]]

**가능한 원인**
1. **I/O Wait (디스크 병목)**
	- 프로세스가 디스크 읽기/쓰기 대기 때문에 응답하지 못하는 경우
	- 느린 디스크나 I/O 스케줄러 문제, 혹은 Ceph/NFS 같은 외부 스토리지 지연일 가능성
2. **CPU 부족**
	- CPU가 100% 점유되어 프로세스가 실행 기회를 얻지 못하는 경우
	- 특히 가상화 환경(KVM, Docker, OpenStack)에서는 다른 VM/컨테이너가 리소스를 독점하면 이런 현상 발생
3. **메모리 압박**
	- 스왑이 과도하게 발생하거나, 메모리가 꽉 차서 프로세스가 응답하지 못하는 경우
	- 네트워크/DB 연동 프로세스가 큐를 쌓아두고 응답하지 못할 때도 흔히 발생
4. **Deadlock**
	- 특정 커널 락/리소스를 기다리다가 풀리지 않아 교착 상태에 빠진 경우

**문제 분석**
`iostat` : CPU와 디스크 I/O 상태
![[Pasted image 20251002163134.png]]
- CPU idle 87% -> CPU 여유 충분
- iowait 0.02% -> 디스크 대기 시간 거의 없음
- sda I/O -> 꾸준히 1MB/s 정도의 읽기/쓰기 -> 정상 범위, 병목 아님
- loop 장치는 주로 Snap 패키지 마운트용 루프 디바이스인데, 성능에 큰 영향 없음
=> CPU, 디스크 모두 정상이고, 병목 현상 없음

`ps -o ...` : 해당 PID의 상태 코드와 스택(trace)
![[Pasted image 20251002164357.png]]
- ==STAT = D== : Uninterruptible sleep (Disk sleep) 상태
	- 프로세스가 커널 내부에서 I/O를 기다리며 빠져나오지 못하는 상태 **(I/O wait)**
	- 이 상태는 `kill -9`로도 종료가 안 됨 (커널이 I/O 응답을 기다리기 때문에)
![[Pasted image 20251002223140.png|300]]
- S : Sleep 상태 (idle 상태에서 대기 중, 보통 요청 대기)
- L : 멀티스레드(Threaded), 즉 `clone_thread` 플래그가 설정된 상태
	- apache2 프로세스는 정상적으로 요청 대기 중이다.
	- (`46165` PID는 과거에 hung 상태에 빠졌던 apache2 worker 프로세스였고, 지금은 재시작되거나 교체된 상태라서 PID가 바뀜)

=> 지금 시점에서는 nova-conductor만 문제 있음
- Apache 로그에 "blocked" 메시지가 남았던 이유는, 과거 특정 시점에 요청 처리 중 DB나 내부 서비스 호출에서 막혀 I/O wait 상태로 빠졌기 때문
- 지금은 워커가 교체/재시작돼서 PID가 달라지고 상태도 S(대기)로 돌아온 것

---
`nova-conductor` 는 **Nova <-> DB (RabbitMQ, MySQL) 통신**을 담당하는 핵심 컴포넌트이다
즉, 아래 요소에서 문제 발생 가능
1. DB 서버(MySQL/MariaDB) 쿼리 응답이 지연
2. 네트워크 문제 (DB 연결 끊김, 패킷 드롭)
3. ~~디스크 I/O 문제 (DB가 디스크 쓰기/읽기 못함 → conductor가 응답 대기)~~ 
   -> 위에서 확인했을 때 정상

[nova-conductor 블로킹 원인 추적]
![[Pasted image 20251002225810.png]]
- **`exc_page_fault`** → nova-conductor 프로세스가 페이지 폴트(Page Fault)를 일으킴
    - 즉, 필요한 메모리 페이지가 RAM에 없어서 → 디스크에서 가져오거나 (swap, 파일 매핑) → KVM 하이퍼바이저에 요청하는 상황
- **`kvm_async_pf_task_wait_schedule` / `__kvm_handle_async_pf`** → KVM 가상화 환경에서 발생하는 **비동기 페이지 폴트(Asynchronous Page Fault, Async PF)** 처리 루틴
    - VM(가상머신) 내부에서 메모리 접근을 했는데, 해당 메모리가 아직 준비되지 않아 Hypervisor(KVM)가 게스트 프로세스를 블록시키고 기다리게 하는 상태

즉, ==**nova-conductor가 DB 호출 중에 필요한 메모리 페이지를 가져오지 못해 KVM 레벨에서 블록**된 상태==임

[열린 FD 수(이상치 확인), 어떤 파일/소켓 대기인지 확인]
![[Pasted image 20251004134618.png]]
- `nova-conductor (PID 22730)`가 연 파일 디스크립터([[FD]])는 18개뿐
- 대부분은 **파이썬 실행파일**, **라이브러리 SO 파일**(`/usr/lib/python3.12`, `msgpack`, `pyvectorc`, `libyaml`) 등 코드 실행에 필요한 shared object
- 특이하게 DB 소켓(`/var/run/mysqld/mysqld.sock`)이나 네트워크 소켓이 이 앞부분 출력에서는 안 보임 → DB 호출 직전에 커널/메모리 단계에서 막혀 있어서 FD에 바로 드러나지 않는 상태일 수 있음

즉, nova-conductor가 엄청난 FD를 쥐고 I/O 폭주 중은 아님. 대신 커널이 페이지를 공급하지 못해서 멈춰있는 게 더 유력

[파일시스템, 페이지캐시 상태 점검]
![[Pasted image 20251004134823.png]]
- **캐시 1.3GB** → 정상적. 여유 메모리 많으니 캐시도 유지
- **SwapCached 380MB** → 일부 페이지가 스왑으로 나갔다가 다시 접근된 상태. 즉, 커널이 swap-in/out을 했던 흔적은 있음
- **Dirty/Writeback 거의 없음** → 디스크에 기록 대기 중인 페이지는 없으므로 I/O write 병목은 아님

결론: VM 내부에서 메모리/디스크 자원은 넉넉, 병목 신호 없음.  
nova-conductor의 D 상태는 내부 리소스 부족이 아닌 **==KVM 호스트 쪽에서의 페이지 폴트 처리 지연 문제==** 이다.

---
[호스트 스왑 비활성화]
스왑을 사용하면 **페이지 폴트 처리 과정이 디스크 I/O에 의존하게 되어 극도로 지연된다.**
스왑 끄는 명령어 : `swapoff -a`
- 끄기 전
	![[Pasted image 20251004191336.png]]
- 끈 후
	![[Pasted image 20251004191401.png]]

스왑 껐더니 대시보드 정상 접속됨! 문제 해결

=> 스왑을 끄니까 문제가 해결된 이유는 **==호스트가 QEMU(=게스트 RAM을 들고 있는 프로세스)의 메모리 페이지를 디스크로 스왑 아웃하지 않게 되었기 때문==** 이다. 그 결과, 게스트가 해당 페이지에 접근할 때 발생하는 **디스크 기반 페이지 폴트 처리(스왑 인 + I/O 대기)** 가 없어져 지연이 사라졌다.

---
### 왜 스왑이 켜져 있으면 느려질까?
**호스트 스왑 → 게스트 느림은 정설**
RHEL 가이드에선 "KVM이 호스트 스왑에 의존하면 게스트가 자주 느려진다"고 못 박고 있고(특히 오버커밋 상황), 그래서 이런 환경에선 스왑을 피하거나 최소화하라고 권장한다.

KVM 호스트에서 QEMU 프로세스가 들고 있는 **게스트 메모리 페이지가 스왑 아웃**되면, 게스트가 그 페이지를 다시 접근할 때 **호스트 → 디스크 I/O → 게스트** 순으로 복구해야한다. 이게 바로 `page supply delay`로 보이는 거고, 스왑을 꺼버리면 이런 thrashing 원천 차단된다.

- 여기서 말하는 게스트(Guest)는 KVM 위에서 동작하는 가상 머신을 뜻한다.
- **호스트(Host)**  
    물리 서버에서 실행 중인 **리눅스 커널 + KVM 모듈 + QEMU 프로세스**
    → 이 레벨이 실제 하드웨어(CPU, 메모리, 디스크, 네트워크)를 직접 제어함
- **게스트(Guest)**  
    호스트 위에서 QEMU/KVM이 가상화해주는 **가상 머신**
    → 게스트는 자기 입장에선 진짜 컴퓨터처럼 보이지만, 실제로는 QEMU가 제공하는 **가상 CPU, 가상 메모리, 가상 디스크** 등을 사용함
- 게스트 메모리 페이지는 VM이 사용하는 메모리 페이지인데, 
  실제로는 호스트에서 실행 중인 QEMU 프로세스의 메모리 공간 일부로 구현되어 있다.

### 스왑을 끄면 무엇이 달라지나?
1. **게스트 메모리 상주성 보장**
   QEMU가 쥔 게스트 RAM이 디스크로 밀려나지 않으니, 게스트가 접근할 때 호스트 디스크 I/O를 기다릴 일이 사라짐 → page supply delay 해소
2. **kswapd/직접 회수(direct reclaim) 소멸**
   vmstat의 `si/so`가 0으로 수렴하고, I/O 대기와 스캔이 크게 줄어든다. (`vmstat 1`, `sar -W 1`, `/proc/vmstat`의 `pswpin/pswpout`로 확인)
